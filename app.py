from flask import Flask, request, jsonify, send_from_directory, render_template_string
from flask_cors import CORS
import openai
import os
from dotenv import load_dotenv
import logging

# Carregar vari√°veis de ambiente
load_dotenv()

app = Flask(__name__, static_folder='.', static_url_path='')
CORS(app)  # Permitir requisi√ß√µes do frontend

# Configurar logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Configurar OpenAI
openai.api_key = os.getenv('OPENAI_API_KEY')
MODEL_NAME = os.getenv('MODEL_NAME')

class AIResponseGenerator:
    """IA 1: Gera resposta sugerida para o ticket"""
    
    @staticmethod
    def generate_response(ticket_description):
        try:
            prompt = f"""
Voc√™ √© um analista de TI experiente. Analise este ticket e forne√ßa uma resposta profissional em texto corrido, sem t√≥picos ou listas.

TICKET: {ticket_description}

Exemplos de bom estilo de resposta:
- "Realizada a√ß√£o de expurgo de dados do HOM/DEV do ambiente de produ√ß√£o. Aproximadamente 40TB. Plano de migra√ß√£o gradual para converter os volumes Thick existentes para o formato Thin Provision."
- "Avaliar viabilidade de atualizar para uma vers√£o mais recente do SMB. Caso seja poss√≠vel, ajustar tamb√©m os par√¢metros de montagem para otimizar o desempenho."
- "Realizar an√°lise das queries em execu√ß√£o no momento da ocorr√™ncia do problema, a fim de identificar poss√≠veis gargalos de desempenho e fatores que contribu√≠ram para a instabilidade."

Forne√ßa uma resposta t√©cnica em texto corrido, explicando a solu√ß√£o de forma natural e fluida. Use par√°grafos apenas se necess√°rio para separar ideias diferentes. Seja conciso mas completo."""

            response = openai.ChatCompletion.create(
                model=MODEL_NAME,
                messages=[
                    {"role": "system", "content": "Voc√™ √© um analista de TI experiente. Responda sempre em texto corrido, sem listas ou t√≥picos. Use linguagem t√©cnica mas natural. M√°ximo 120 palavras."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=180,
                temperature=0.4
            )
            
            return {
                "success": True,
                "response": response.choices[0].message.content.strip()
            }
            
        except Exception as e:
            logger.error(f"Erro ao gerar resposta da IA: {str(e)}")
            return {
                "success": False,
                "error": f"Erro ao gerar resposta: {str(e)}"
            }

class AIQualityEvaluator:
    """IA 2: Avalia qualidade e acur√°cia da resposta do analista"""
    
    @staticmethod
    def evaluate_response(ticket_description, analyst_response, ai_suggested_response):
        try:
            prompt = f"""
Compare e avalie a resposta do analista em rela√ß√£o √† solu√ß√£o ideal da IA:

TICKET: {ticket_description}

RESPOSTA DO ANALISTA: {analyst_response}

RESPOSTA IDEAL DA IA: {ai_suggested_response}

Avalie o qu√£o pr√≥xima a resposta do analista est√° da resposta ideal, considerando:
- Precis√£o t√©cnica: O analista demonstra o mesmo n√≠vel de conhecimento t√©cnico?
- Completude: A solu√ß√£o do analista aborda os mesmos pontos essenciais da IA?
- Clareza: A comunica√ß√£o √© t√£o clara quanto a resposta de refer√™ncia?
- Adequa√ß√£o: A resposta est√° alinhada com a abordagem ideal para o problema?

- N√£o seja muito r√≠gido na avalia√ß√£o, por√©m s√©rio e seja flex√≠vel e considere o contexto do ticket e a resposta do analista.

Formato OBRIGAT√ìRIO:
SCORE: [n√∫mero 0-100 baseado na proximidade com a resposta ideal]
PRECIS√ÉO: [0-25] - Compara√ß√£o do conhecimento t√©cnico demonstrado versus resposta ideal.
COMPLETUDE: [0-25] - Compara√ß√£o da abrang√™ncia da solu√ß√£o versus resposta ideal.
CLAREZA: [0-25] - Compara√ß√£o da clareza comunicativa versus resposta ideal.
ADEQUA√á√ÉO: [0-25] - Compara√ß√£o do alinhamento ao problema versus resposta ideal.
RESUMO: An√°lise de quanto a resposta do analista se aproxima da qualidade e abordagem da resposta ideal."""

            response = openai.ChatCompletion.create(
                model=MODEL_NAME,
                messages=[
                    {"role": "system", "content": "Voc√™ √© um supervisor de qualidade em TI. Compare a resposta do analista com a resposta ideal da IA para medir proximidade e qualidade. Avalie objetivamente o grau de acur√°cia. Use texto corrido. M√°ximo 120 palavras."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=160,
                temperature=0.3
            )
            
            evaluation_text = response.choices[0].message.content.strip()
            
            # Extrair score do texto
            score = AIQualityEvaluator._extract_score(evaluation_text)
            
            return {
                "success": True,
                "score": score,
                "evaluation": evaluation_text,
                "quality_level": AIQualityEvaluator._get_quality_level(score)
            }
            
        except Exception as e:
            logger.error(f"Erro ao avaliar resposta: {str(e)}")
            return {
                "success": False,
                "error": f"Erro ao avaliar resposta: {str(e)}"
            }
    
    @staticmethod
    def _extract_score(evaluation_text):
        """Extrai o score num√©rico do texto de avalia√ß√£o"""
        try:
            lines = evaluation_text.split('\n')
            for line in lines:
                if 'SCORE:' in line.upper():
                    score_text = line.split(':')[-1].strip()
                    # Extrair apenas n√∫meros
                    import re
                    numbers = re.findall(r'\d+', score_text)
                    if numbers:
                        score = int(numbers[0])
                        return min(100, max(0, score))  # Garantir entre 0-100
            return 0
        except:
            return 0
    
    @staticmethod
    def _get_quality_level(score):
        """Determina o n√≠vel de qualidade baseado no score"""
        if score >= 90:
            return "Excelente"
        elif score >= 80:
            return "Muito Bom"
        elif score >= 70:
            return "Bom"
        elif score >= 60:
            return "Satisfat√≥rio"
        elif score >= 50:
            return "Precisa Melhorar"
        else:
            return "Inadequado"

@app.route('/')
def home():
    """Servir a p√°gina principal HTML"""
    try:
        return send_from_directory('.', 'index.html')
    except:
        return jsonify({
            "message": "GLPI AI - Avaliador de Respostas API",
            "status": "online",
            "endpoints": ["/evaluate", "/health"],
            "note": "Coloque os arquivos index.html, styles.css, script.js e glpi.png na mesma pasta do app.py"
        })

@app.route('/<path:filename>')
def serve_static(filename):
    """Servir arquivos est√°ticos (CSS, JS, imagens)"""
    try:
        return send_from_directory('.', filename)
    except:
        return jsonify({"error": f"Arquivo {filename} n√£o encontrado"}), 404

@app.route('/api')
def api_info():
    """Informa√ß√µes da API"""
    return jsonify({
        "message": "GLPI AI - Avaliador de Respostas API",
        "status": "online",
        "endpoints": ["/evaluate", "/health"]
    })

@app.route('/evaluate', methods=['POST'])
def evaluate():
    try:
        data = request.get_json()
        
        if not data:
            return jsonify({"error": "Dados n√£o fornecidos"}), 400
        
        ticket = data.get('ticket', '').strip()
        analyst_response = data.get('analyst_response', '').strip()
        
        if not ticket or not analyst_response:
            return jsonify({"error": "Ticket e resposta do analista s√£o obrigat√≥rios"}), 400
        
        logger.info(f"Processando avalia√ß√£o para ticket: {ticket[:50]}...")
        
        # IA 1: Gerar resposta sugerida
        logger.info("Gerando resposta sugerida pela IA...")
        ai_response_result = AIResponseGenerator.generate_response(ticket)
        
        if not ai_response_result["success"]:
            return jsonify({"error": ai_response_result["error"]}), 500
        
        ai_suggested_response = ai_response_result["response"]
        
        # IA 2: Avaliar qualidade da resposta do analista
        logger.info("Avaliando qualidade da resposta do analista...")
        evaluation_result = AIQualityEvaluator.evaluate_response(
            ticket, analyst_response, ai_suggested_response
        )
        
        if not evaluation_result["success"]:
            return jsonify({"error": evaluation_result["error"]}), 500
        
        # Resposta final
        result = {
            "success": True,
            "ai_suggested_response": ai_suggested_response,
            "evaluation": {
                "score": evaluation_result["score"],
                "quality_level": evaluation_result["quality_level"],
                "detailed_evaluation": evaluation_result["evaluation"]
            }
        }
        
        logger.info(f"Avalia√ß√£o conclu√≠da. Score: {evaluation_result['score']}")
        return jsonify(result)
        
    except Exception as e:
        logger.error(f"Erro no endpoint /evaluate: {str(e)}")
        return jsonify({"error": f"Erro interno: {str(e)}"}), 500

@app.route('/health', methods=['GET'])
def health_check():
    """Endpoint para verificar sa√∫de da API"""
    try:
        # Testar conex√£o com OpenAI
        openai.Model.list()
        return jsonify({
            "status": "healthy",
            "openai_connection": "ok",
            "model": MODEL_NAME
        })
    except Exception as e:
        return jsonify({
            "status": "unhealthy",
            "openai_connection": "error",
            "error": str(e)
        }), 500

if __name__ == '__main__':
    # Verificar se a chave da API est√° configurada
    if not os.getenv('OPENAI_API_KEY'):
        logger.error("OPENAI_API_KEY n√£o encontrada no arquivo .env")
        exit(1)
    
    logger.info("üöÄ Iniciando GLPI AI - Avaliador de Respostas...")
    logger.info(f"üìä Modelo configurado: {MODEL_NAME}")
    logger.info("üåê Servidor rodando em: http://localhost:5000")
    logger.info("üì± Interface web dispon√≠vel na raiz: /")
    logger.info("üîß API endpoints: /evaluate, /health, /api")
    
    app.run(debug=True, host='0.0.0.0', port=5000)
